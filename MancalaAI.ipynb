{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bac9d248",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# CSCI 3202, Fall 2023\n",
    "# Mancala Project - Outline\n",
    "# Caleb Lehman\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab038773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy, math, time, random\n",
    "random.seed(109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MancalaAI:\n",
    "    def __init__(self, depth, state):\n",
    "        \n",
    "        self.depth = depth\n",
    "        self.state = state\n",
    "    \n",
    "    def valid_moves(self,state,player):\n",
    "\n",
    "        moves = []\n",
    "        if player == 1:\n",
    "\n",
    "            for i in range(state.pits_per_player):\n",
    "                if state.board[i] > 0:\n",
    "                    moves.append(i+1)\n",
    "        \n",
    "        if player == 2:\n",
    "\n",
    "            for i in range(state.pits_per_player):\n",
    "                if state.board[i+state.pits_per_player + 1] > 0:\n",
    "                    moves.append(i+1)\n",
    "\n",
    "        return moves\n",
    "\n",
    "\n",
    "    def minimax(self, state, depth, maximizing_player, cur_player):\n",
    "        \n",
    "        # stop condition, game is over or depth has been reached\n",
    "\n",
    "        if depth == 0 or state.winning_eval() == True:\n",
    "            return self.evaluate_state(state)\n",
    "        \n",
    "        \n",
    "        if maximizing_player:\n",
    "            # generate all possible states for the maximizing player, and recurse \n",
    "            # until you reach the stop condition - terminal state\n",
    "\n",
    "            value = -100000\n",
    "            possible_valid_moves = self.valid_moves(state,1)\n",
    "            \n",
    "            for i in range(len(possible_valid_moves)):\n",
    "                \n",
    "                game = copy.deepcopy(state)\n",
    "                game.play(possible_valid_moves[i],1)\n",
    "\n",
    "                value = max(value,self.minimax(game, depth-1, False,2)) # minimizing players' move\n",
    "        else:\n",
    "            # generate all possible states for the maximizing player, and recurse\n",
    "            \n",
    "            value = 100000\n",
    "            possible_valid_moves = self.valid_moves(state,2)\n",
    "            \n",
    "            for i in range(len(possible_valid_moves)):\n",
    "                \n",
    "                game = copy.deepcopy(state)\n",
    "                game.play(possible_valid_moves[i],2)\n",
    "\n",
    "                value = min(value,self.minimax(game, depth-1, True, 1)) # maximizing players' move\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def minimax_alpha_beta(self, state, depth, alpha, beta, maximizing_player, cur_player):\n",
    "        \n",
    "        if depth == 0 or state.winning_eval() == True:\n",
    "            return self.evaluate_state(state)\n",
    "        \n",
    "\n",
    "        if maximizing_player:\n",
    "\n",
    "            value = -100000\n",
    "            possible_valid_moves = self.valid_moves(state,1)\n",
    "\n",
    "            for i in range(len(possible_valid_moves)):\n",
    "\n",
    "                game = copy.deepcopy(state)\n",
    "                game.play(possible_valid_moves[i],1)\n",
    "\n",
    "                value = max(value,self.minimax_alpha_beta(game,depth -1,alpha,beta,False,2))\n",
    "\n",
    "                if value >= beta:\n",
    "                    \n",
    "                    return value\n",
    "                    \n",
    "                \n",
    "                alpha = max(alpha,value)\n",
    "        \n",
    "        else:\n",
    "            value = 100000\n",
    "            possible_valid_moves = self.valid_moves(state,2)\n",
    "\n",
    "            for i in range(len(possible_valid_moves)):\n",
    "\n",
    "                game = copy.deepcopy(state)\n",
    "                game.play(possible_valid_moves[i],2)\n",
    "\n",
    "                value = min(value,self.minimax_alpha_beta(game,depth-1,alpha,beta,True,1))\n",
    "\n",
    "                if value <= alpha:\n",
    "                    \n",
    "                    return value\n",
    "                    \n",
    "                    \n",
    "                beta = min(beta,value)\n",
    "        \n",
    "        return value\n",
    "\n",
    "\n",
    "\n",
    "    def best_move(self, state,cur_player, alpha_beta = False):\n",
    "        \n",
    "        if cur_player == 1:\n",
    "            \n",
    "            other_player = 2\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            other_player = 1\n",
    "\n",
    "\n",
    "        if alpha_beta == False:\n",
    "\n",
    "            possible_valid_moves = self.valid_moves(state,cur_player)\n",
    "\n",
    "            best_move = possible_valid_moves[0]\n",
    "\n",
    "            value = -1000000\n",
    "\n",
    "            for i in range(len(possible_valid_moves)):\n",
    "\n",
    "                game = copy.deepcopy(state)\n",
    "\n",
    "                game.play(possible_valid_moves[i],cur_player)\n",
    "\n",
    "                if cur_player == 2:\n",
    "                    maximizing_player = True\n",
    "                else:\n",
    "                    maximizing_player = False\n",
    "\n",
    "                val = self.minimax(game,self.depth,maximizing_player,other_player)\n",
    "\n",
    "                if val > value:\n",
    "                    value = val\n",
    "                    best_move = possible_valid_moves[i]\n",
    "\n",
    "            return best_move\n",
    "\n",
    "        else:\n",
    "\n",
    "            possible_valid_moves = self.valid_moves(state,cur_player)\n",
    "\n",
    "            best_move = possible_valid_moves[0]\n",
    "\n",
    "            value = -100000\n",
    "\n",
    "            alpha = -10000000\n",
    "            beta  =  10000000\n",
    "\n",
    "            for i in range(len(possible_valid_moves)):\n",
    "\n",
    "                game = copy.deepcopy(state) \n",
    "\n",
    "                game.play(possible_valid_moves[i],cur_player)\n",
    "\n",
    "                if cur_player == 2:\n",
    "                    maximizing_player = True\n",
    "                else:\n",
    "                    maximizing_player = False\n",
    "                \n",
    "                val = self.minimax_alpha_beta(game,self.depth,alpha,beta,maximizing_player,other_player)\n",
    "\n",
    "                if val > value:\n",
    "                    value = val\n",
    "                    best_move = possible_valid_moves[i]\n",
    "            \n",
    "            return best_move\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def evaluate_state(self, state):\n",
    "        # Utility function  :- Difference between P1 mancala and p2 mancala\n",
    "        return state.board[state.p1_mancala_index] - state.board[state.p2_mancala_index]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92af0ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class Mancala:\n",
    "    def __init__(self, pits_per_player=6, stones_per_pit = 4):\n",
    "        self.pits_per_player = pits_per_player\n",
    "        self.stones_per_pit = stones_per_pit\n",
    "        self.board = [stones_per_pit] * ((pits_per_player + 1) * 2)\n",
    "        self.players = 2\n",
    "        self.current_player = 1\n",
    "        self.moves = []\n",
    "        self.p1_pits_index = [0, self.pits_per_player-1]\n",
    "        self.p1_mancala_index = self.pits_per_player\n",
    "        self.p2_pits_index = [self.pits_per_player + 1, len(self.board) - 2]\n",
    "        self.p2_mancala_index = len(self.board) - 1\n",
    "    \n",
    "        self.num_plays = 0\n",
    "        self.board[self.p1_mancala_index] = 0\n",
    "        self.board[self.p2_mancala_index] = 0\n",
    "        self.p1_wins = 0\n",
    "        self.p2_wins = 0\n",
    "        self.ties = 0\n",
    "        \n",
    "\n",
    "    def display_board(self):\n",
    "        player_1_pits = self.board[self.p1_pits_index[0]: self.p1_pits_index[1] + 1]\n",
    "        player_1_mancala = self.board[self.p1_mancala_index]\n",
    "        player_2_pits = self.board[self.p2_pits_index[0]: self.p2_pits_index[1] + 1]\n",
    "        player_2_mancala = self.board[self.p2_mancala_index]\n",
    "\n",
    "        print('P1               P2')\n",
    "        print('     ____{}____     '.format(player_2_mancala))\n",
    "        for i in range(self.pits_per_player):\n",
    "            if i == self.pits_per_player - 1:\n",
    "                print('{} -> |_{}_|_{}_| <- {}'.format(i + 1, player_1_pits[i], player_2_pits[-(i + 1)],\n",
    "                                                       self.pits_per_player - i))\n",
    "            else:\n",
    "                print('{} -> | {} | {} | <- {}'.format(i + 1, player_1_pits[i], player_2_pits[-(i + 1)],\n",
    "                                                      self.pits_per_player - i))\n",
    "\n",
    "        print('         {}         '.format(player_1_mancala))\n",
    "        turn = 'P1' if self.current_player == 1 else 'P2'\n",
    "        print('Turn: ' + turn)\n",
    "    \n",
    "    def random_move_generator(self,cur_player):\n",
    "        \"\"\"\n",
    "        Function to generate random valid moves with non-empty pits for the random player\n",
    "        \"\"\"\n",
    "\n",
    "        if self.winning_eval() == True:\n",
    "            return -1\n",
    "        \n",
    "        val = random.randint(1,self.pits_per_player)\n",
    "\n",
    "        while self.valid_move(val,cur_player) == False:\n",
    "            val = random.randint(1,self.pits_per_player)\n",
    "        \n",
    "        return val\n",
    "        \n",
    "        \n",
    "    def generate_board(self):\n",
    "        self.board = [self.stones_per_pit] * ((self.pits_per_player+1) * 2)\n",
    "        self.current_player = 1\n",
    "        self.moves = []\n",
    "        self.board[self.p1_mancala_index] = 0\n",
    "        self.board[self.p2_mancala_index] = 0\n",
    "\n",
    "    def valid_move(self, pit,cur_player):\n",
    "\n",
    "        if cur_player == 1:\n",
    "            if pit > self.pits_per_player or self.board[pit-1] == 0:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        else:\n",
    "            if pit > self.pits_per_player or self.board[pit + self.pits_per_player] == 0:\n",
    "                return False\n",
    "            else:\n",
    "                return True        \n",
    "      \n",
    "       \n",
    "        \n",
    "\n",
    "    def play(self, pit, cur_player, debug = False):\n",
    "        \n",
    "        if pit == -1:\n",
    "            return True\n",
    "        \n",
    "        if self.valid_move(pit,cur_player) == False:\n",
    "            print(\"invalid move\")\n",
    "            return True\n",
    "        \n",
    "        if cur_player == 1:\n",
    "                \n",
    "            stones = self.board[pit-1]\n",
    "            \n",
    "            index = 0\n",
    "\n",
    "            for i in range(stones):\n",
    "                \n",
    "                self.board[pit - 1] = self.board[pit - 1] - 1\n",
    "\n",
    "                index = ( (pit + i) % len(self.board))\n",
    "\n",
    "                if index == self.p2_mancala_index:\n",
    "                        stones = stones + 1\n",
    "                        \n",
    "                else:\n",
    "                    self.board[index] = self.board[index] + 1\n",
    "                    \n",
    "            if index < self.p1_mancala_index and self.board[index] == 1 and self.board[self.p1_mancala_index + (self.p1_mancala_index - index)] != 0:\n",
    "                opp = self.p1_mancala_index + (self.p1_mancala_index - index)\n",
    "\n",
    "                self.board[self.p1_mancala_index] = self.board[self.p1_mancala_index] + 1 + self.board[opp]\n",
    "\n",
    "                self.board[index] = 0\n",
    "                self.board[opp] = 0\n",
    "                    \n",
    "                \n",
    "                self.moves.append((1,pit))\n",
    "                self.current_player = 2\n",
    "\n",
    "                \n",
    "        if cur_player == 2:\n",
    "\n",
    "                start = pit + self.pits_per_player\n",
    "                stones = self.board[start]\n",
    "\n",
    "                index = 0\n",
    "                for i in range(stones):\n",
    "                    self.board[start]  = self.board[start] -1\n",
    "\n",
    "                    index = (start + i + 1) % (len(self.board))\n",
    "                        \n",
    "\n",
    "                    if index == self.p2_mancala_index:\n",
    "                        self.board[self.p2_mancala_index] = self.board[self.p2_mancala_index] + 1\n",
    "\n",
    "                    elif index == self.p1_mancala_index:\n",
    "                        stones = stones + 1\n",
    "                    else:\n",
    "                        self.board[index] = self.board[index] + 1\n",
    "\n",
    "                if index != self.p2_mancala_index and index > self.p1_mancala_index and self.board[index] == 1 and self.board[self.p1_mancala_index - (index - self.p1_mancala_index)] != 0:\n",
    "                    opp = self.p1_mancala_index - (index - self.p1_mancala_index)\n",
    "\n",
    "                    self.board[self.p2_mancala_index] = self.board[self.p2_mancala_index] + 1 + self.board[opp]\n",
    "\n",
    "                    self.board[index] = 0\n",
    "                    self.board[opp] = 0\n",
    "                    \n",
    "                \n",
    "                self.moves.append((2,pit))\n",
    "                self.current_player = 1\n",
    "\n",
    "            \n",
    "            \n",
    "        self.num_plays = self.num_plays + 1\n",
    "\n",
    "        return self.winning_eval()\n",
    "\n",
    "\n",
    "\n",
    "    def winning_eval(self):\n",
    "        \n",
    "        game_over1 = True\n",
    "        game_over2 = True\n",
    "\n",
    "        for i in range(self.pits_per_player):\n",
    "            if self.board[i] > 0:\n",
    "                game_over1 = False\n",
    "        \n",
    "        for i in range(self.pits_per_player + 1, len(self.board)-1):\n",
    "            if self.board[i] > 0:\n",
    "                game_over2 = False\n",
    "        \n",
    "        if game_over1 or game_over2:\n",
    "\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def points(self):\n",
    "        \n",
    "        if self.board[self.p1_mancala_index] > self.board[self.p2_mancala_index]:\n",
    "                self.p1_wins = self.p1_wins + 1\n",
    "            \n",
    "        if self.board[self.p2_mancala_index] > self.board[self.p1_mancala_index]:\n",
    "                self.p2_wins = self.p2_wins +1\n",
    "            \n",
    "        if self.board[self.p1_mancala_index] == self.board[self.p2_mancala_index]:\n",
    "                self.ties = self.ties + 1\n",
    "    \n",
    "    def rand_match_analysis(self, games = 100):\n",
    "        \n",
    "        for i in range(games):\n",
    "\n",
    "            move = False\n",
    "            \n",
    "            while move == False:\n",
    "                \n",
    "                \n",
    "                move = self.play(self.random_move_generator(1),1,False)\n",
    "               \n",
    "\n",
    "                self.num_plays = self.num_plays + 1\n",
    "                if move == True:\n",
    "                    break\n",
    "\n",
    "                move = self.play(self.random_move_generator(2),2,False)\n",
    "                self.num_plays = self.num_plays + 1\n",
    "            \n",
    "            self.points()\n",
    "\n",
    "            self.generate_board()\n",
    "    \n",
    "    \n",
    "    def AI_vs_rand(self,depth,games):\n",
    "        \n",
    "        for i in range(games):\n",
    "\n",
    "            move = False\n",
    "\n",
    "            while move == False:\n",
    "\n",
    "                AI = MancalaAI(depth,self)\n",
    "\n",
    "                game = copy.deepcopy(self)\n",
    "\n",
    "                AI_move = AI.best_move(game,1,False)\n",
    "\n",
    "\n",
    "                move = self.play(AI_move,1,False)\n",
    "\n",
    "                self.num_plays = self.num_plays+1\n",
    "\n",
    "                if move == True:\n",
    "                    break\n",
    "\n",
    "                move = self.play(self.random_move_generator(2),2,False)\n",
    "                self.num_plays = self.num_plays + 1\n",
    "            \n",
    "            self.points()\n",
    "\n",
    "            self.generate_board()\n",
    "    \n",
    "    def AI_alpha_beta_vs_rand(self,depth,games):\n",
    "\n",
    "        for i in range(games):\n",
    "\n",
    "            move = False\n",
    "\n",
    "            while move == False:\n",
    "\n",
    "                AI = MancalaAI(depth,self)\n",
    "\n",
    "                game = copy.deepcopy(self)\n",
    "\n",
    "                AI_move = AI.best_move(game,1,True)\n",
    "\n",
    "                move = self.play(AI_move,1,False)\n",
    "\n",
    "                self.num_plays = self.num_plays + 1\n",
    "\n",
    "                if move == True:\n",
    "                    break\n",
    "\n",
    "                move = self.play(self.random_move_generator(2),2,False)\n",
    "                self.num_plays = self.num_plays + 1\n",
    "            \n",
    "            self.points()\n",
    "\n",
    "            self.generate_board()\n",
    "\n",
    "\n",
    "                \n",
    "\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0313ea48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1 wins: 49\n",
      "P2 wins: 43\n",
      "Ties: 8\n",
      "Avg Plays: 80.84\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##1. Run 100 games of random vs random\n",
    "\n",
    "rand_game = Mancala()\n",
    "\n",
    "num_games = 100\n",
    "rand_game.rand_match_analysis(num_games)\n",
    "\n",
    "print(\"P1 wins: \" + str(rand_game.p1_wins))\n",
    "print(\"P2 wins: \" + str(rand_game.p2_wins))\n",
    "print(\"Ties: \"+ str(rand_game.ties))\n",
    "print(\"Avg Plays: \"+ str(rand_game.num_plays/num_games))\n",
    "\n",
    "# On the first time compiling, we see 49 wins for player one, 43 for player two, and 8 ties, with an average game lasting around 81 plays\n",
    "# So the win percenage is around 50% for any of the players, which makes sense as both are playing randomly\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17056efb",
   "metadata": {},
   "source": [
    "So, after playing 100 games of randomly chosen moves from both players, we can see that the winrate for p1 hovers around 50%. Depending on the seed or how many times it was compiled, p2 could win more often. So, we can argue that the winrate is around 50% when placing two random opponants against eachother.\n",
    "\n",
    "This is expected as every move is chosen randomly; however, you could argue that player 1 might have a higher than 50% winrate, simply due to the fact that the first person has first move advantage. Looking at a sample of 10,000 games, p1 did win more often than p2, almost confirming a first move advantage in this game. So on a smaller sample size of 100 games, it would be hard to see, but on a larger sample size, we can argue that player 1 will win more often than not, even if both players choose pits randomlly.\n",
    "\n",
    "Each game takes around 80 to 90 moves to complete, meaning each player gets around 40 to 45 turns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI wins: 100\n",
      "Random player wins: 0\n",
      "Ties: 0\n",
      "Avg number of plays:63.1\n"
     ]
    }
   ],
   "source": [
    "## AI versus random player, 100 games, depth of 5 piles, no alpha beta\n",
    "\n",
    "gameAI = Mancala()\n",
    "\n",
    "gameAI.AI_vs_rand(5,100)\n",
    "\n",
    "print(\"AI wins: \" + str(gameAI.p1_wins))\n",
    "print(\"Random player wins: \" + str(gameAI.p2_wins))\n",
    "print(\"Ties: \" + str(gameAI.ties))\n",
    "print(\"Avg number of plays:\" + str(gameAI.num_plays/100))\n",
    "\n",
    "## On first compilation with a depth of five piles, the AI bot will always win every game. To play the 100 games, it usually takes anywhere between 4 to 4 and a half minutes.\n",
    "## on average, there are about 60 to 65 turns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e21017",
   "metadata": {},
   "source": [
    "Above are the results for the minimax algorithm with a depth of 5 piles against a random player. The AI will win 100% of the games. Even at a depth of 2 piles, it will win every game. \n",
    "\n",
    "This algorithm usually takes anywhere from 4 to 4 and a half minutes to play 100 games,  and has an average number of moves around 60 to 66 moves, so each player got around 30 to 33 turns.\n",
    "\n",
    "I would say that the AI player is definitively better than random chance. Even looking at the AI with 0 piles, it still wins over 90% of the time. Once you add the ability for the AI to look deeper into the game, it will never lose. The goal of the AI is to maximize the difference between the stones in each players mancala, which is how you win the game. It will always be able to do this more optimally than the random opponent. You could argue that if the random opponent played some exact move order, it could beat the AI; however, given a sample size of finite games, the AI will always perform better than random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4a8d023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI wins: 100\n",
      "Random player wins: 0\n",
      "Ties: 0\n",
      "Avg number of plays:61.22\n"
     ]
    }
   ],
   "source": [
    "## AI using alpha beta minmax vs random player, 100 games, depth of 5 piles\n",
    "\n",
    "gameAI = Mancala()\n",
    "\n",
    "gameAI.AI_alpha_beta_vs_rand(5,100)\n",
    "\n",
    "print(\"AI wins: \" + str(gameAI.p1_wins))\n",
    "print(\"Random player wins: \" + str(gameAI.p2_wins))\n",
    "print(\"Ties: \" + str(gameAI.ties))\n",
    "print(\"Avg number of plays:\" + str(gameAI.num_plays/100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29980df4",
   "metadata": {},
   "source": [
    "Here we are again using the minimax algorithm with a depth of 5 piles, but also including the alpha beta algorithm to prune non-optimal branches. The AI still won 100% of the games.\n",
    "\n",
    "However, looking at the run time, we can see that it takes anywhere from 1 to 1 and half minutes, meaning the alpha beta version of minimax runs 70% faster, while still winning every game against the random opponent. Each game took around .6 to .9 seconds to complete.\n",
    "\n",
    "Here, the amount of moves to win is still around the same, with each player getting around 30 to 33 turns.\n",
    "\n",
    "The minimax alpha beta function will do the same thing as the normal minimax function, just in a faster time. The alpha beta allows non optimal branches to be pruned which saves time, but since those pruned branches had no optimal moves, the normal minimax function would not have picked them anyways. So, ideally given the same board, both minimax and alpha beta minimax will pick the same optimal move and should win in the same number of turns, but alpha beta minimax will do it in a much quicker time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0585b8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## AI using alpha beta with depth of 10 piles\n",
    "\n",
    "\n",
    "gameAI = Mancala()\n",
    "\n",
    "gameAI.AI_alpha_beta_vs_rand(10,100)\n",
    "\n",
    "print(\"AI wins: \" + str(gameAI.p1_wins))\n",
    "print(\"Random player wins: \" + str(gameAI.p2_wins))\n",
    "print(\"Ties\" + str(gameAI.ties))\n",
    "print(\"Avg number of plays:\" + str(gameAI.num_plays/100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ec117",
   "metadata": {},
   "source": [
    "The 100 games at 10 piles is currently running while I am typing this, and will probably be running for long after I finish. I tried the alpha beta minimax algorithm with a depth of 10 piles for one game, and it took around 1 and a half minutes to finish. So, 100 games should take over 2 hours to run. \n",
    "\n",
    "My educated guess is that this AI will win 100% of the games, as even with only 1 - 2 piles, the AI won every game. Increasing the number of piles will most likely cut down slightly on move count, but in my opinion, is not worth the cost and time it takes to run.\n",
    "\n",
    "If the AI is already winning 100 percent of the games and the goal is only to win, there is no reason to keep increasing the pile count. If we wanted to optimize play and move count, we can see that increasing the number of piles exponentially increases the run time. If the goal was to optimize play while also winning, it might be better to keep a middle ground depth, while changing our utility function to increase play optimization.\n",
    "\n",
    "\n",
    "The 100 games at depth 10 piles took 168 minutes to run. It had an average of 68.5 moves, which is similar to the games with lower pile counts. So, in fact, increasing the number of piles had little to no impact on the move count. From this, it would be safe to say that increasing the depth of piles is not the best way to increase efficiency of play. A far better choice would be to adjust the utility function, or modify the decision making algorithm.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
